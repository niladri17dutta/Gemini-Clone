# Gemini Clone

This is a Gemini AI clone built using React and integrated with the Gemini API. The app replicates the functionality of the original Gemini chatbot, allowing users to interact with AI seamlessly.

## Features

- ğŸŒŸ **Real-time AI interaction** powered by the Gemini API
- âš›ï¸ **React-based front-end** for smooth and dynamic UI
- ğŸš€ **Fast and responsive** design
- ğŸ”’ **API integration** with secure key handling

## Installation

1. **Clone the repository**

```bash
git clone https://github.com/niladri17dutta/Gemini-Clone.git
cd Gemini-Clone
```

2. **Install dependencies**

```bash
npm install
```

3. **Create a `.env` file** in the root directory and add your Gemini API key:

```
REACT_APP_GEMINI_API_KEY=your_api_key_here
```

4. **Start the development server**

```bash
npm start dev
```

The app should now be running at `http://localhost:3000`

## Usage

- Type your prompt in the input field
- Press "Submit" to send the prompt to the Gemini API
- Receive AI-generated responses instantly

## Project Structure

```
.
â”œâ”€â”€ public
â”œâ”€â”€ src
|   â”œâ”€â”€ assets
â”‚   â”œâ”€â”€ components
â”‚   â”‚   â”œâ”€â”€ Main
â”‚   â”‚   |   |â”€â”€ Main.css
â”‚   â”‚   |   â””â”€â”€ Main.jsx
|   |   â”œâ”€â”€ Sidebar
â”‚   â”‚   |   |â”€â”€ Sidebar.css
â”‚   â”‚   |   â””â”€â”€ Sidebar.jsx
â”‚   â”œâ”€â”€ config
â”‚   â”‚   â””â”€â”€ gemini.js
â”‚   â”œâ”€â”€ context
â”‚   â”‚   â””â”€â”€ Context.jsx
â”‚   â”œâ”€â”€ App.jsx
â”‚   â”œâ”€â”€ index.css
â”‚   â””â”€â”€ main.jsx
â”œâ”€â”€ .eslintrc.cjs
â”œâ”€â”€ .gitignore
â”œâ”€â”€ eslint.config.js
â”œâ”€â”€ index.html
â”œâ”€â”€ package-lock.json
â”œâ”€â”€ package.json
â”œâ”€â”€ vite.config.js
â””â”€â”€ README.md
```

## API Integration

The API requests are handled in `src/config/gemini.js`:

```javascript
const API_kEY = "YOUR-API-KEY";
const genAI = new GoogleGenerativeAI(API_kEY);

const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash-8b" });

const generationConfig = {
    temperature: 0.9,
    topP: 1,
    topK: 1,
    maxOutputTokens: 2048,
    responseMimeType: "text/plain",
};

async function run(prompt) {
    const chatSession = model.startChat({
        generationConfig,
        history: [],
    });

    const result = await chatSession.sendMessage(prompt);
    const response = result.response;
    console.log(result.response.text());
    return response.text();
}

export default run;
```

## Contributing

Feel free to fork this repository, open an issue, or submit a pull request if you'd like to enhance the app!

## License

This project is licensed under the MIT License.

---

### âœ¨ Happy Coding! âœ¨
